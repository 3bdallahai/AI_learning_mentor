# 🤖 AI Learning Mentor

## ✨ Overview

The AI Learning Mentor is a specialized Retrieval-Augmented Generation (RAG) application designed to answer complex questions from uploaded source materials (books, documents) with high fidelity. Its primary goal is to serve as an expert tutor, especially for technical subjects like Artificial Intelligence (AI), by leveraging an LLM with precise, extracted context from user-provided books.

## 🎯 Key Features

### Document Ingestion: 
Supports uploading PDFs and TXT files to build a reliable knowledge base.

### Cloud Storage: 
Stores all raw documents and generated vector embeddings securely on AWS S3.

### Metadata Management: 
Persists document metadata, file paths, and cache records in a MySQL server.

### Robust Text Processing: 
Utilizes PyMuPDF (fitz) for efficient and accurate text extraction from PDF files.

### Advanced Embedding: 
Text is chunked into 500-token segments and embedded using the high-performance SentenceTransformer ("all-MiniLM-L6-v2").

### High-Speed Retrieval: 
Context is retrieved quickly and efficiently using an index powered by the FAISS library.

### Reliable LLM: 
Answers are generated by the fine-tuned Qwen2.5-0.5B-Instruct model, ensuring focused and context-aware responses.

### Measured Accuracy: 
Achieves a measured faithfulness score of 9.5/10 to 10/10 (assessed via an external LLM ), guaranteeing answers are firmly grounded in the source context.

### Intelligent Caching: 
Implements a similarity-based cache on the MySQL database. If a new user query exceeds a 0.9 similarity threshold to a previous query, the cached answer is returned, significantly reducing LLM inference costs and latency.

### FastAPI Backend: 
Provides a robust, scalable backend with dedicated routes for all core functionalities:

* /documents: Lists all uploaded documents and supports document deletion from the cloud.

* /upload: Handles the file upload process to S3.

* /query: Manages the RAG pipeline, serving answers from the cache or generating new responses via the LLM.

## 🛠️ Tech Stack



* Backend Framework

FastAPI -> 
High-performance, asynchronous Python web framework.

* LLM

Qwen2.5-0.5B-Instruct ->
The core model is used for generating final answers.

* Database

MySQL ->
Used for metadata and query caching.

* Cloud

AWS S3 ->
Storage for source documents and vector embeddings.

Text Processing

PyMuPDF (fitz) ->
For efficient PDF text extraction.

* Embeddings

Sentence-Transformers
Specifically "all-MiniLM-L6-v2".

* Vector Search

FAISS ->
Facebook AI Similarity Search for fast index retrieval.

## Dependencies

requirements.txt

All required Python libraries are listed here.

📁 Project Structure

The application is designed to be modular and easy to navigate:

>├── .env  
├── app   
│   ├── core  
│   │   └── config.py  
│   ├── db    
│   │   ├── database.py  
│   │   └── models.py  
│   ├── rag  
│   │   ├── embedder.py  
│   │   ├── qa_chain.py  
│   │   ├── retriever.py  
│   │   ├── text_extraction.py  
│   │   └── vector_store.py  
│   ├── routes  
│   │   ├── documents.py  
│   │   ├── health.py  
│   │   ├── init.py  
│   │   ├── query.py  
│   │   └── upload.py  
│   └── utils  
│       ├── common.py   
│       └── init.py  
├── main.py  
└── requirements.txt  

## 🚀 Getting Started

### Prerequisites

Python 3.8+

pip (Python package installer)

Access to a MySQL server.

An AWS S3 bucket and corresponding credentials.

### Installation

#### Clone the repository:
    
>git clone [Your Repository URL]
>cd AI_learning_mentor
   

#### Create and activate a virtual environment (recommended):

>python -m venv venv
>source venv/bin/activate  # On Linux/macOS
>.\venv\Scripts\activate   # On Windows


#### Install the dependencies:

> pip install -r requirements.txt


## Configuration

Set up environment variables for the application. It is recommended to use a .env file in the root directory.

### AWS:

>AWS_ACCESS_KEY_ID=your_key
>AWS_SECRET_ACCESS_KEY=your_secret
>AWS_S3_BUCKET_NAME=your-bucket-name


### MySQL:

>DATABASE_URL=mysql+pymysql://user:password@host:port/dbname


### LLM: 
Ensure the model files (Qwen2.5-0.5B-Instruct) are accessible to the application, typically by configuring the model path or API key if using a service.

## 🏃 Usage

### 1. Run the FastAPI Server

Start the application using uvicorn:

>uvicorn app.main:app --reload
Access the API at [http://127.0.0.1:8000](http://127.0.0.1:8000)


You can view the interactive API documentation at http://127.0.0.1:8000/docs.

### 2. Upload a Document

Use the /upload endpoint to add a new book or document to the knowledge base:

Endpoint: POST /upload/

Action: Send a file (e.g., a PDF or TXT) in the request body.

### 3. Query the Mentor

Use the /query endpoint to ask a question. The request includes the document name to restrict the search, and the question itself.

Endpoint: POST /query/

#### Example Request (using curl):

curl -X 'POST' \
  '[http://127.0.0.1:8000/query/](http://127.0.0.1:8000/query/)' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "doc_name": "eBook-How-to-Build-a-Career-in-AI.pdf",
    "question": "How can I start a new career in AI?"
  }'


#### Example Response:

{
  "answer": {
    "final_answer": "To start a new career in AI, it's essential to gather valuable insights from experts like Andrew Ng, 
    who has extensive experience in the field. Start by collecting data on the current trends and advancements in AI technology. Next, 
    focus on developing technical skills relevant to your desired career path. Consider taking courses or workshops to enhance your knowledge and skills.
    Additionally, explore opportunities within your industry or join professional organizations to network and gain exposure. 
    Finally, develop a detailed project plan to showcase your expertise and contribute to the advancement of AI technology.",   
    "context_used": [
      "conducting a handful  of informational interviews...",
      "rapid rise in AI jobs, and many people are building exciting  careers in this field...",
      "PAGE 1 Founder, DeepLearning.AI Collected Insights from Andrew Ng How to  Build Your Career in AI..."
    ]
  },  
  "source": "llm"    
  /* Source will be "cache" if similarity > 0.9, otherwise "llm" */
}
